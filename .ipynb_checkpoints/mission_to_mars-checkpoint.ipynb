{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\sabun\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.20\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Create an executable path\n",
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hear Audio From NASA's Perseverance As It Travels Through Deep Space\n",
      "The first to be rigged with microphones, the agency's latest Mars rover picked up the subtle sounds of its own inner workings during interplanetary flight.\n"
     ]
    }
   ],
   "source": [
    "#part 1 Retriving the news Article title and paragragph\n",
    "#reference Day 2 most activities\n",
    "marURL= 'https://mars.nasa.gov/news/'\n",
    "browser.visit(marURL)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# HTML object\n",
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "item_list = soup.find('ul', class_ = 'item_list')\n",
    "slide = item_list.find('li', class_ = 'slide')\n",
    "#Activity 7\n",
    "#get title\n",
    "news_title = slide.find('div', class_ = 'content_title').text\n",
    "#get paragragp\n",
    "news_p = slide.find('div', class_ = 'article_teaser_body').text\n",
    "\n",
    "#verigy they are correct\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5803a0003c90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mjpg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#combine the link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Part 2 Getting Photo from jpl\n",
    "\n",
    "jplURL = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(jplURL)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# HTML object\n",
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Day 2 activity 8 \n",
    "#click on the box to access the image\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "\n",
    "# HTML object\n",
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#ref https://stackoverflow.com/questions/2136267/beautiful-soup-and-extracting-a-div-and-its-contents-by-id\n",
    "box = soup.find('div',{\"id\": \"fancybox-lock\"})\n",
    "# box = soup.find('div',class_=\"fancybox-inner fancybox-skin fancybox-dark-skin fancybox-dark-skin-open\")\n",
    "\n",
    "jpg = box.find('img')['src']\n",
    "\n",
    "#combine the link\n",
    "featured_image_url = f'https://www.jpl.nasa.gov{jpg}'\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3 Mars Fact\n",
    "#Day 2 Activity 9-10\n",
    "\n",
    "factURL = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(factURL)\n",
    "#checking what kind of tables we have we will pick either the first one or the second one\n",
    "tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marsTables = tables[0]\n",
    "\n",
    "#assigning labesl \n",
    "marsTables.columns = ['', 'Mars']\n",
    "marsTables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = marsTables.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Part 4 Hemisphere Image\n",
    "hemisphere_image_urls = []\n",
    "hemURL = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemURL)\n",
    "# HTML object\n",
    "html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "item = soup.find('div', class_ = 'collapsible results').find_all('div', class_ = 'item')\n",
    "\n",
    "for hem in item:\n",
    "    #image title\n",
    "    imgTitle = hem.find('h3').text\n",
    "    #click on the link to get larger images size\n",
    "    browser.click_link_by_partial_text(imgTitle)\n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    imgURL = soup.find('div', class_ = 'downloads').find('li').find('a')['href']\n",
    "    \n",
    "    dictionary = {\"Title\" : imgTitle, \"img_url\": imgURL}\n",
    "    hemisphere_image_urls.append(dictionary)\n",
    "    #moving back on the browser https://splinter.readthedocs.io/en/latest/browser.html\n",
    "    browser.back()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
